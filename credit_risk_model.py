# -*- coding: utf-8 -*-
"""credit_risk_model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qsu9iblOxvTTyhIDGe3nVplo1ktyBF_a
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report

def load_data(path):
    """
    Fungsi untuk memuat data dari file CSV.
    """
    print("Loading data...")
    try:
        df = pd.read_csv(path)
        print(f"Data berhasil dimuat! Shape awal: {df.shape}")
        return df
    except FileNotFoundError:
        print(f"Error: File '{path}' tidak ditemukan.")
        return None
def preprocess_data(df):
    """
    Fungsi untuk membersihkan dan memproses data:
    1. Filter target (Fully Paid & Charged Off)
    2. Encoding Target
    3. Feature Engineering (Regex untuk cleaning text)
    4. Imputasi (Mengisi nilai kosong dengan Median)
    """
    print("Preprocessing data...")

    # 1. Filter Target Variable
    df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])].copy()

    # 2. Encoding Target (0 = Good, 1 = Bad)
    df['target'] = df['loan_status'].map({
        'Fully Paid': 0,
        'Charged Off': 1
    })

    # 3. Select Features
    features = ['loan_amnt', 'term', 'int_rate', 'annual_inc', 'dti', 'emp_length']
    X = df[features].copy()
    y = df['target']

    # 4. Feature Engineering (Cleaning text to numbers)
    # Menggunakan raw string r'' agar aman dari warning regex
    X['term'] = X['term'].astype(str).str.extract(r'(\d+)').astype(float)
    X['emp_length'] = X['emp_length'].astype(str).str.extract(r'(\d+)').astype(float)

    # 5. Imputasi (PENTING: Mengisi data kosong dengan Median)
    # Kita simpan nama kolomnya agar tidak hilang setelah imputasi
    imputer = SimpleImputer(strategy='median')
    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=features)

    return X_imputed, y

def train_model(X, y):
    """
    Fungsi untuk melatih model.
    Menggunakan Class Weight 'balanced' untuk mengatasi ketimpangan data.
    """
    print("Training model...")

    # Split Data (80% Train, 20% Test)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Scaling
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Model Training
    # class_weight='balanced' membantu menaikkan Recall Bad Loan
    model = RandomForestClassifier(n_estimators=100,
                                   class_weight='balanced',
                                   random_state=42)
    model.fit(X_train_scaled, y_train)

    return model, scaler, X_test_scaled, y_test

def evaluate_and_save(model, scaler, X_test, y_test, threshold=0.2):
    """
    Evaluasi model dengan Threshold Kustom (0.2) dan simpan model.
    """
    print(f"\nEvaluating model (dengan Threshold {threshold})...")

    # Prediksi Probabilitas
    y_prob = model.predict_proba(X_test)[:, 1]

    # Terapkan Threshold 0.2 (Sesuai temuan eksperimen)
    y_pred_adj = (y_prob >= threshold).astype(int)

    # Tampilkan Hasil
    print(f"ROC-AUC Score: {roc_auc_score(y_test, y_prob):.2f}")
    print("-" * 30)
    print("Classification Report (Threshold Optimized):")
    print(classification_report(y_test, y_pred_adj))

    # Simpan Model & Scaler
    print("-" * 30)
    print("Saving model assets...")
    joblib.dump(model, 'credit_risk_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    print("SUCCESS: Model 'credit_risk_model.pkl' dan 'scaler.pkl' berhasil disimpan.")

if __name__ == "__main__":
    # === ALUR KERJA UTAMA (END-TO-END) ===

    # 1. Tentukan path file csv
    data_path = "loan_data_2007_2014.csv"

    # 2. Load Data
    df = load_data(data_path)

    if df is not None:
        # 3. Preprocessing
        X, y = preprocess_data(df)

        # 4. Training
        model, scaler, X_test_scaled, y_test = train_model(X, y)

        # 5. Evaluasi & Simpan (Menggunakan Threshold 0.2)
        evaluate_and_save(model, scaler, X_test_scaled, y_test, threshold=0.2)